{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from krazy_gridworld import KrazyGridWorld\n",
    "import numpy as np\n",
    "import torch\n",
    "from model import Model\n",
    "from utils import ReplayBuffer, get_state, sample_advice, advice_satisfied\n",
    "from itertools import count\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME='ACTRCE(-)-sparse_reward-delayed_board_update' + ' ' + datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "max_frames = int(2e5)\n",
    "save_interval = 100\n",
    "train_frequency = 2\n",
    "log_frequency = 1000\n",
    "initial_board_update = 40000\n",
    "board_update_frequency = 4000\n",
    "\n",
    "lr=1e-3\n",
    "batch_size = 64\n",
    "T=25\n",
    "\n",
    "log_dir = f'/mnt/hdd1/ml/logs/{NAME}'\n",
    "SAVE_DIR = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = KrazyGridWorld()\n",
    "env.reset()\n",
    "channel_in, height, width = get_state(env).shape\n",
    "action_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log_dir is None:\n",
    "    writer = None\n",
    "else:\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(lr, height, width, channel_in, action_dim, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_decay(frame_number, eps_init=1.0, eps_end=0.01, decay_len=100000):\n",
    "    if frame_number > decay_len:\n",
    "        return eps_end\n",
    "    else:\n",
    "        return eps_init * (1-frame_number/decay_len) + eps_end * (frame_number/decay_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate_step = []\n",
    "success_rate_value = []\n",
    "loss_rate_step = []\n",
    "loss_rate_value = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_number = 0\n",
    "success = 0\n",
    "num_episodes = 0\n",
    "dqn_num = 0\n",
    "reset_counter = 0\n",
    "while frame_number < max_frames:\n",
    "    if reset_counter > board_update_frequency and frame_number > initial_board_update:\n",
    "        env.reset(reset_agent_start_pos=True, reset_board=True)\n",
    "        reset_counter = 0\n",
    "    else:\n",
    "        env.reset(reset_agent_start_pos=True)\n",
    "    advice = sample_advice()\n",
    "    replay_buffer.new_episode()\n",
    "    for t in range(T):\n",
    "        frame_number += 1\n",
    "        reset_counter += 1\n",
    "        state = get_state(env)\n",
    "        eps = epsilon_decay(frame_number)\n",
    "        action = net.select_action(state, advice.split(\" \"), dqn_num, epsilon=eps)\n",
    "            \n",
    "        _, _, done, info = env.step(action)\n",
    "        at_goal = env.at_goal()\n",
    "        is_lava = env.is_dead()\n",
    "        color = info['color']\n",
    "        next_state = get_state(env)\n",
    "                    \n",
    "        done = done \n",
    "        satisfied = advice_satisfied(advice, color, at_goal, is_lava)\n",
    "            \n",
    "        replay_buffer.add(state, action, next_state, float(done), color, at_goal, is_lava)\n",
    "            \n",
    "        if frame_number % train_frequency == 0:\n",
    "            loss = net.update(batch_size, replay_buffer, (dqn_num + 1) % 2)\n",
    "            if writer is not None and loss is not None:\n",
    "                writer.add_scalar(\"loss\", loss, frame_number)\n",
    "                loss_rate_step.append(frame_number)\n",
    "                loss_rate_value.append(loss)\n",
    "                \n",
    "        if frame_number % log_frequency == 0 and writer is not None:\n",
    "            writer.add_scalar('success_rate', success/num_episodes, frame_number)\n",
    "            success_rate_step.append(frame_number)\n",
    "            success_rate_value.append(success/num_episodes)\n",
    "            success = 0\n",
    "            num_episodes = 0\n",
    "            \n",
    "        if done or t == T - 1 or satisfied:\n",
    "            replay_buffer.compute_reward(color, at_goal, is_lava)\n",
    "            if satisfied:\n",
    "                success += 1\n",
    "            num_episodes += 1\n",
    "            break    \n",
    "                \n",
    "    dqn_num = (dqn_num + 1) % 2\n",
    "        \n",
    "#     if episode % save_interval == 0:\n",
    "#         print(f'model saved on episode: {episode % (10 * save_interval)}')\n",
    "#         net.save('models', f'episode-{episode % (10 * save_interval)}')\n",
    "        \n",
    "#         print(f'best model saved with reward: {total_rewards}')\n",
    "#         net.save('models', f'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_rate_step, loss_rate_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success rate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(success_rate_step, success_rate_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
